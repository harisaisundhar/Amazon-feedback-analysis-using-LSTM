{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_abst_LSTM_Attention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkjUWQDtu-lu",
        "colab_type": "text"
      },
      "source": [
        "# **Abstractive Text Summarization using LSTM**\n",
        "\n",
        "### Model presented for Machine Learning Project\n",
        "\n",
        "- Harisaipravin Sv \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCS7sud8C_vD",
        "colab_type": "text"
      },
      "source": [
        "*# A neural network is considered to be an effort to mimic human brain actions in a simplified manner. Attention Mechanism is also an attempt to implement the same action of selectively concentrating on a few relevant things, while ignoring others in deep neural networks.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM5ll7z9SoxG",
        "colab_type": "text"
      },
      "source": [
        "ATTENTION LAYER DEFINITION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTnyOFtdQ4WT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Attention Layer focusses on one part of the data at a time just like humans, instead of looking all at a time which proved to be forgetfull in RNN"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Fi64aA0FFxcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Keras support Attention Layer Library, We gathered idea from that and tried implementing on our own without going for library\n",
        "import tensorflow as Tensor_f # Tensorflow supports for Keras\n",
        "from tensorflow.python.keras.layers import Layer # Keras provide LSTM suppport\n",
        "from tensorflow.python.keras import backend as Keras_p # Backend Layer\n",
        "\n",
        "# Attention Layer reads word by word just like a human interpretter\n",
        "# In case of attention Layer All the data is fed through every iteration along with the previous result from the before iteration\n",
        "# It does this instead of just sending the previous result and thus allowing it to remember much data\n",
        "class Algo_attention(Layer):\n",
        "# This is the class from which all layers inherit. A layer is a callable object that takes as input one or more tensors and the outputs one or more tensors.\n",
        "\n",
        "    def __init__(self, **kwargs): #constructor \n",
        "        super(Algo_attention, self).__init__(**kwargs) #avoid referring to the base class explicitly\n",
        "\n",
        "    # Layers -> “forget gate layer”, “input gate layer”, “output gate layer”\n",
        "    # Layers involves a *state* (weight variables), defined in the `build()` method.\n",
        "    def build(self, input_shape): # keras default function to build\n",
        "        assert isinstance(input_shape, list) # Assert lets you test if a condition in your code returns True, if not, the program will raise an AssertionError\n",
        "        # Creates the state of the Layer\n",
        "        # Weighted vector creation for the attention layer to be trained\n",
        "        # The distribution of the input shape to accomodate every value in vertical, horizontal and Diagonal axis\n",
        "        self.Xval = self.add_weight(name='Xval', shape=Tensor_f.TensorShape((input_shape[0][2], input_shape[0][2])), trainable=True, initializer='uniform') # horizontal line over matrix\n",
        "        self.Yval = self.add_weight(name='Yval', shape=Tensor_f.TensorShape((input_shape[1][2], input_shape[0][2])), trainable=True, initializer='uniform') # verrical line over matrix\n",
        "        self.Zval = self.add_weight(name='Zval', shape=Tensor_f.TensorShape((input_shape[0][2], 1)), trainable=True, initializer='uniform') # Diagonal line, 1 stands for input_shape[2][2]\n",
        "        super(Algo_attention, self).build(input_shape) # Allows callback within the program instead of creating instance everytime\n",
        "\n",
        "    # Layer involves *computation*, defined in the `call()` method\n",
        "    def call(self, inputs, verbose=False): \n",
        "        assert type(inputs) == list # For Debugging\n",
        "        crypt, decrypt = inputs # Encode and Decode value both initialized to input at first\n",
        "        \n",
        "        # Function to create a tensor data\n",
        "        def start_func(inputs, hidden_size):\n",
        "            tempdata= Keras_p.zeros_like(inputs)  # 0 array of input size\n",
        "            tempdata= Keras_p.sum(tempdata, axis=[1, 2])  #Summing the tempdata with values of first two axes which has data from first 2 LSTM models\n",
        "            tempdata= Keras_p.expand_dims(tempdata) # Adds the third dimension to the tempdata array\n",
        "            tempdata= Keras_p.tile(tempdata, [1, hidden_size])  # Creates the tensor of size [1, hidden_size] from the temp data value \n",
        "            return tempdata\n",
        "\n",
        "        # sum function to return list\n",
        "        def process_func(inputs, states):\n",
        "            temp = Keras_p.sum(crypt * Keras_p.expand_dims(inputs, -1), axis=1) #sum of values along the axis 1\n",
        "            return temp, [temp] #returns list\n",
        "\n",
        "        #Applying formula to the input\n",
        "        def eprocess_func(inputs, states):\n",
        "            message = \"Input must be of type list\".format(states, type(states)) # checks input from process_func\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), message # for debugging it prints the message\n",
        "\n",
        "            # Shapeing the input for alying formula\n",
        "            h_data =  crypt.shape[2] # encoder data 2nd col \n",
        "            r_output = Keras_p.reshape(crypt, (-1, h_data)) # reshaping encoder data\n",
        "            s_length = crypt.shape[1] # encoder data 1st col\n",
        "            Yval_dot_h = Keras_p.expand_dims(Keras_p.dot(inputs, self.Yval), 1)  # Adds dimension of size Yval\n",
        "            Xval_dot_s = Keras_p.reshape(Keras_p.dot(r_output, self.Xval), (-1, s_length, h_data)) # multiples two tensors and returns them\n",
        "            \n",
        "            # Attenntion layer involves banck and forth checks\n",
        "            # It iterates the string from first to last and last to first \n",
        "            r_model = Keras_p.tanh(Keras_p.reshape(Xval_dot_s + Yval_dot_h, (-1, h_data))) # Element-wise tanh returning the array of size h_data\n",
        "            keras_d = Keras_p.reshape(Keras_p.dot(r_model, self.Zval), (-1, s_length)) # Multiples the num(r_model) \n",
        "            keras_d = Keras_p.softmax(keras_d) # Softmax converts a real vector to a vector of categorical probabilities, cuz max of (a)t is 1\n",
        "            return keras_d, [keras_d]\n",
        "        \n",
        "        tempdata_e = start_func(crypt, crypt.shape[1])  #Tensordata created\n",
        "        tempdata_c = start_func(crypt, crypt.shape[-1])\n",
        "        #Iterates over the time dimension of a tensor\n",
        "        final_t, results, _ = Keras_p.rnn(eprocess_func, decrypt, [tempdata_e],) #Encode RNN\n",
        "        final_t, c_outputs, _ = Keras_p.rnn(process_func, results, [tempdata_c],) #Decode RNN\n",
        "\n",
        "        return c_outputs, results"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a652VwM2SUin",
        "colab_type": "text"
      },
      "source": [
        "## DATA PREPERATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "_Jpu8qLEFxcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords # frequently used words like a, an , the , etc\n",
        "from tensorflow.keras.callbacks import EarlyStopping # To stop when Model converges\n",
        "from tensorflow.keras.models import Model # To build a Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed # LSTM Support using keras\n",
        "from bs4 import BeautifulSoup # Remoeving html tags\n",
        "from keras.preprocessing.text import Tokenizer  # vectorize a text \n",
        "from keras.preprocessing.sequence import pad_sequences # ensure that all sequences in a list have the same size\n",
        "import warnings # To omit warnings\n",
        "import numpy as np # NumPy is used for working with arrays\n",
        "import pandas as pd # Manupulating data with dataframe\n",
        "import re #regular expressions to be removed"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7Z1fRxXCPaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "warnings.filterwarnings(\"ignore\") #Ignore unnecessary warnings\n",
        "pd.set_option(\"display.max_colwidth\", 100) # Panda max_col_width set to 100 as it exceeds in some eror cases"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvfzpqYH8N24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive # Pydrive helps in mouting dataset to collab\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials  #oauth2 support given\n",
        " \n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default() # prompt to sign in\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1_aUwPQLt7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "154c5293-7ee4-4316-c371-04d8ece93caa"
      },
      "source": [
        "file_list = drive.ListFile({'q': \"'file_id_to_be_added_here' in parents and trashed=false\"}).GetList() # folder_id posted here\n",
        "for file1 in file_list:\n",
        "  print('%s -> %s' % (file1['title'], file1['id'])) # List of files in the folder"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reviews.csv -> 1\n",
            "hashes.txt -> 2\n",
            "database.sqlite -> 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBXPbiTa9Kn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f_id=''\n",
        "drive_file = drive.CreateFile({'id': f_id})\n",
        "drive_file = drive.CreateFile({'id':'id_here_to_be_added'}) #file_id to mount\n",
        "drive_file.GetContentFile('Reviews.csv') #getfile"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wnK5o4Z1Fxcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "record=pd.read_csv(\"Reviews.csv\",nrows=100000) #Read file"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Cjul88oOFxcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "record.drop_duplicates(subset=['Text'],inplace=True) # Drop duplicates\n",
        "record.dropna(axis=0,inplace=True) # Drop records with missing data or Null"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPkN-MgAD_um",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "5a4b34cd-97e0-4415-f8df-53a84315777f"
      },
      "source": [
        "record.info() #Record Schema"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 88421 entries, 0 to 99999\n",
            "Data columns (total 10 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   Id                      88421 non-null  int64 \n",
            " 1   ProductId               88421 non-null  object\n",
            " 2   UserId                  88421 non-null  object\n",
            " 3   ProfileName             88421 non-null  object\n",
            " 4   HelpfulnessNumerator    88421 non-null  int64 \n",
            " 5   HelpfulnessDenominator  88421 non-null  int64 \n",
            " 6   Score                   88421 non-null  int64 \n",
            " 7   Time                    88421 non-null  int64 \n",
            " 8   Summary                 88421 non-null  object\n",
            " 9   Text                    88421 non-null  object\n",
            "dtypes: int64(5), object(5)\n",
            "memory usage: 7.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUwo8zmR_uJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "a013a338-5601-40ca-e4b5-eb7e7c55a628"
      },
      "source": [
        "record.head() #Record Preview"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned dog food products and have found them all to be of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very qu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                                                                                 Text\n",
              "0   1  ...  I have bought several of the Vitality canned dog food products and have found them all to be of ...\n",
              "1   2  ...  Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted...\n",
              "2   3  ...  This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelati...\n",
              "3   4  ...  If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got thi...\n",
              "4   5  ...  Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very qu...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0s6IY-x2FxdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Common Conjugations words\n",
        "spams = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG9qf5AjFEku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "58d91139-d2fc-4edf-d04d-5ae7db9c8871"
      },
      "source": [
        "import nltk # Library for stowords\n",
        "nltk.download('stopwords') #Stopwords\n",
        "word_s = set(stopwords.words('english')) # Stopwords of english language"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XZr-u3OEFxdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_data(text,num):\n",
        "    buffer = text.lower() \n",
        "    buffer = BeautifulSoup(buffer, \"lxml\").text # Handling XML and HTML related datas by converting to text\n",
        "    buffer = re.sub(r'\\([^)]*\\)', '', buffer) #removing unnecessary datas\n",
        "    buffer = re.sub('\"','', buffer) # clearing double quotes \n",
        "    buffer = ' '.join([spams[t] if t in spams else t for t in buffer.split(\" \")]) # removing spam words\n",
        "    buffer = re.sub(r\"'s\\b\",\"\",buffer) # plurals and empty string\n",
        "    buffer = re.sub(\"[^a-zA-Z]\", \" \", buffer) #special characters removed\n",
        "    buffer = re.sub('[m]{2,}', 'mm', buffer) # remove repeating words\n",
        "\n",
        "    if(num==0):\n",
        "        tokens = [w for w in buffer.split() if not w in word_s] #first cleanup removing stowords\n",
        "    else:\n",
        "        tokens=buffer.split() #second cleanup seperating them\n",
        "        \n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                               \n",
        "            long_words.append(i) #records having more than 1 words still\n",
        "    return (\" \".join(long_words)).strip()"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "A2QAeCHWFxdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_data = [] # processed text\n",
        "for t in record['Text']:\n",
        "    processed_data.append(clean_data(t,0)) # List appending"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NCAIkhWbFxdh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "9820f51b-7691-4263-9c0f-6d7eb4bb5d60"
      },
      "source": [
        "processed_data[:10]  # Top 10 text datas"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
              " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
              " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
              " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
              " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal',\n",
              " 'got wild hair taffy ordered five pound bag taffy enjoyable many flavors watermelon root beer melon peppermint grape etc complaint bit much red black licorice flavored pieces kids husband lasted two weeks would recommend brand taffy delightful treat',\n",
              " 'saltwater taffy great flavors soft chewy candy individually wrapped well none candies stuck together happen expensive version fralinger would highly recommend candy served beach themed party everyone loved',\n",
              " 'taffy good soft chewy flavors amazing would definitely recommend buying satisfying',\n",
              " 'right mostly sprouting cats eat grass love rotate around wheatgrass rye',\n",
              " 'healthy dog food good digestion also good small puppies dog eats required amount every feeding']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GsRXocxoFxd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary_data = [] # processed summary\n",
        "for t in record['Summary']:\n",
        "    summary_data.append(clean_data(t,1)) # List appending"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jQJdZcAzFxee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "fd89871e-1d15-4099-e0ed-34e34991848f"
      },
      "source": [
        "summary_data[:10] # Top 10 summary datas"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good quality dog food',\n",
              " 'not as advertised',\n",
              " 'delight says it all',\n",
              " 'cough medicine',\n",
              " 'great taffy',\n",
              " 'nice taffy',\n",
              " 'great just as good as the expensive brands',\n",
              " 'wonderful tasty taffy',\n",
              " 'yay barley',\n",
              " 'healthy dog food']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "L1zLpnqsFxey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "record['processed_data']=processed_data\n",
        "record['summary_data']=summary_data"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sYK390unFxfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "record.replace('', np.nan, inplace=True) # remove NaN values,not a proper number\n",
        "record.dropna(axis=0,inplace=True) # remove Null values"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MdF76AHHFxgw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "afff0c8f-1f1d-42fe-dca4-fb498035c51c"
      },
      "source": [
        "# word count graph for text feedback\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Array initialization\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "for cnts in record['processed_data']:\n",
        "      text_word_count.append(len(cnts.split())) # split and append\n",
        "\n",
        "data_len = pd.DataFrame({'text':text_word_count}) # Dataframe conversion\n",
        "data_len.hist(bins = 50) # number of histogram bins to display to make th graph clear to understand\n",
        "plt.ylabel('freq')\n",
        "plt.xlabel('words count')\n",
        "plt.show() # Outputs the graph"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyY2j-CmDbny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "f32f8245-ca03-49ac-8cf6-bcdad67ac79b"
      },
      "source": [
        "# word count graph for summary\n",
        "\n",
        "for cnts in record['summary_data']:\n",
        "      summary_word_count.append(len(cnts.split())) # List append\n",
        "\n",
        "data_len = pd.DataFrame({'summary':summary_word_count}) # two-dimensional size-mutable, heterogeneous tabular data structure for further and easier calclulations with the data\n",
        "\n",
        "data_len.hist(bins = 50) # number of histogram bins to display to make th graph clear to understand\n",
        "plt.ylabel('freq')\n",
        "plt.xlabel('Words count')\n",
        "plt.show() # Outputs the graph"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZKD5VOWqFxhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_T_L=30 #Limiting max legth of the text to 30\n",
        "MAX_S_L=8  #Limiting max legth of the tsummary to 8"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yY0tEJP0FxhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_data=np.array(record['processed_data']) #numpy conversion for array of text records\n",
        "summary_data=np.array(record['summary_data']) #numpy conversion for array of summary records\n",
        "\n",
        "# Array initializatiomn\n",
        "txt_array=[]\n",
        "sum_array=[]\n",
        "\n",
        "for cnts in range(len(processed_data)):\n",
        "    if(len(summary_data[cnts].split())<=MAX_S_L and len(processed_data[cnts].split())<=MAX_T_L): #condition check if the data falls below the Max range category\n",
        "        txt_array.append(processed_data[cnts]) # text appending to array\n",
        "        sum_array.append(summary_data[cnts]) # summary appending to array\n",
        "        \n",
        "Panda_data=pd.DataFrame({'text':txt_array,'summary':sum_array}) #panda conversion dor dataframe"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EwLUH78CFxhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Panda_data['summary'] = Panda_data['summary'].apply(lambda x : 'sostok '+ x + ' eostok') # x = 'sostok '+ x + ' eostok' sentinalvalue"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RakakKHcFxhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split as tts\n",
        "# Split arrays or matrices into random train and test subsets from the loaded data\n",
        "train_x,value_x,train_y,value_y=tts(np.array(Panda_data['text']),np.array(Panda_data['summary']),test_size=0.1,random_state=0,shuffle=True) \n",
        "# train_x for tex\n",
        "# train_y for summary"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oRHTgX6hFxhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer # allows to tokenize texts\n",
        "from keras.preprocessing.sequence import pad_sequences # pad_sequences is used to ensure that all sequences in a list have the same length"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_Qf49oRUMRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dx_tok = Tokenizer()  # tokenizer initiallization\n",
        "dx_tok.fit_on_texts(list(train_x)) # Updates internal vocabulary based on a list of texts"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLVQZdDxWHhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check rare elements try 1\n",
        "escape_val=4 # max number of 4 repeats allowed for texts\n",
        "# 4 is taken becus text is big compared to summary and can have many repeating words\n",
        "# declaring variables\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab_type": "code",
        "id": "Y_tGuVeFxxyA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7838ac2c-0244-4722-aafa-d86d42e64380"
      },
      "source": [
        "for key,value in dx_tok.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1 # number of words in text data ->distinct words\n",
        "    tot_freq=tot_freq+value # total number of words\n",
        "    if(value<escape_val): # if word count freq < 4\n",
        "        cnt=cnt+1 # summary with rare text\n",
        "        freq=freq+value # rare word with freq<4 found\n",
        "    \n",
        "print(\"% of rare words in data:\",(cnt/tot_cnt)*100)\n",
        "print(\"Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in data: 66.12339930151339\n",
            "Coverage of rare words: 2.953684513790566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "J2giEsF3Fxh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_x = Tokenizer(num_words=tot_cnt-cnt)  # tokenizer initiallization\n",
        "tokens_x.fit_on_texts(list(train_x)) # Updates internal vocabulary based on a list of texts\n",
        "\n",
        "value_x_seq = tokens_x.texts_to_sequences(value_x) # Transforms each text in texts to a sequence of integers from word_index dictionary\n",
        "value_x = pad_sequences(value_x_seq, maxlen=MAX_T_L, padding='post') # checks if all records in the list are of same size or it apends 0 post the given record untill it matches MAX_T_L\n",
        "\n",
        "train_x_seq = tokens_x.texts_to_sequences(train_x) # Transforms each text in texts to a sequence of integers from word_index dictionary\n",
        "train_x = pad_sequences(train_x_seq, maxlen=MAX_T_L, padding='post') # checks if all records in the list are of same size or it apends 0 post the given record untill it matches MAX_T_L\n",
        "\n",
        "final_x = tokens_x.num_words + 1 # Total words in the record +1 for NULL"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DCbGMsm4FxiA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0c1e3d4-f4e5-4d17-cb1f-eb605e40d4a0"
      },
      "source": [
        "final_x # Total text word count -> distinct words in text"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8440"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eRHqyBkBFxiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# allows to vectorize a text corpus, by turning each text into a vector where the coefficient for each token is based on word count\n",
        "tokens_y = Tokenizer()   \n",
        "tokens_y.fit_on_texts(list(train_y)) # Updates internal vocabulary based on a list of texts"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2osgTgHtXV2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check rare elements try 2\n",
        "escape_val=6  # max number of 6 repeats of word allowed throughout the file for summary\n",
        "# 6 is taken as summary data is already minimized from data preprocessing\n",
        "# declaring variables\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yzE5OiRLFxiM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2d6634b3-6d95-4260-bb35-33d470c6611c"
      },
      "source": [
        "for key,value in tokens_y.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1 # number of words in summary data ->distinct words\n",
        "    tot_freq=tot_freq+value # total number of words in summary data\n",
        "    if(value<escape_val):\n",
        "        cnt=cnt+1 # rare words count -> distinct rare words\n",
        "        freq=freq+value # total number of rare words\n",
        "        \n",
        "print(\"% of rare words in data:\",(cnt/tot_cnt)*100)\n",
        "print(\"Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in data: 78.12740675541863\n",
            "Coverage of rare words: 5.3921899389571895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-fswLvIgFxiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_y = Tokenizer(num_words=tot_cnt-cnt) # tokenizer initiallization\n",
        "tokens_y.fit_on_texts(list(train_y)) # Updates internal vocabulary based on a list of texts\n",
        "\n",
        "train_y_seq    =   tokens_y.texts_to_sequences(train_y) # Transforms each text in texts to a sequence of integers from word_index dictionary\n",
        "train_y    =   pad_sequences(train_y_seq, maxlen=MAX_S_L, padding='post') # checks if all records in the list are of same size or it apends 0 post the given record untill it matches MAX_T_L\n",
        "\n",
        "value_y_seq   =   tokens_y.texts_to_sequences(value_y) # Transforms each text in texts to a sequence of integers from word_index dictionary\n",
        "value_y   =   pad_sequences(value_y_seq, maxlen=MAX_S_L, padding='post') # checks if all records in the list are of same size or it apends 0 post the given record untill it matches MAX_T_L\n",
        "\n",
        "final_y  =   tokens_y.num_words +1 # Total words in the record +1 for NULL"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kasY707LX2OX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf48beff-a54b-481b-b0d6-9de6c936a0e1"
      },
      "source": [
        "final_y # Total summary word count -> distinct words in summary"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1989"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pR8IX9FRFxiY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "681a0169-6c9d-41a3-fb61-7a8f8488af97"
      },
      "source": [
        "tokens_y.word_counts['sostok'],len(train_y) # Total words read in Summary (Repetition allowed) is equal to summary dataset length\n",
        "# The correctness of model evaluated here"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42453, 42453)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kZ-vW82sFxih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cache=[] # Array initialization\n",
        "for i in range(len(train_y)): # Runs every record as a sentence summary\n",
        "    cnt=0\n",
        "    for j in train_y[i]: # checks for every word in a sentence\n",
        "        if j!=0:\n",
        "            cnt=cnt+1 # cnt increases\n",
        "    if(cnt==2):\n",
        "        cache.append(i) # append the value to cache\n",
        "\n",
        "train_y=np.delete(train_y,cache, axis=0) # Cache removed from axis 0 in Summary\n",
        "train_x=np.delete(train_x,cache, axis=0) # Cache removed from axis 0 in Texts"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cx5NISuMFxik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now since it's removed from dataset it must be removed from value also, failing to do this may result in data inconsistency\n",
        "# As a data shown in value_x and y may not be actually available in the data set\n",
        "\n",
        "cache=[] # Array initialization\n",
        "for i in range(len(value_y)): # Runs every index of the record\n",
        "    cnt=0\n",
        "    for j in value_y[i]: # checks element in the row\n",
        "        if j!=0:\n",
        "            cnt=cnt+1 # cnt increases\n",
        "    if(cnt==2):\n",
        "        cache.append(i) # append the value to cache\n",
        "\n",
        "# As seen from the graph there is a steep increase in the word count for 2, which slows down the process, hence it's removed\n",
        "\n",
        "value_y=np.delete(value_y,cache, axis=0) # Cache removed from axis 0 in Summary\n",
        "value_x=np.delete(value_x,cache, axis=0) # Cache removed from axis 0 in Texts\n",
        "\n",
        "# Now even though removed sepreately both should be in sync"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOtlDcthFxip",
        "colab_type": "text"
      },
      "source": [
        "# Model building\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwuJ2iElyDOA",
        "colab_type": "text"
      },
      "source": [
        "Why LSTM?\n",
        "\n",
        "Long Short-Term Memory (LSTM) networks can convey information in the long term. Different from the traditional RNN, inside each LSTM cell, there are several simple linear operations which allow data to be conveyed without doing the complex computation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zXef38nBFxir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "4ae36d64-e5c5-4416-f346-90e9c6b7eb01"
      },
      "source": [
        "# Layers -> “forget gate layer”, “input gate layer”, “output gate layer”\n",
        "\n",
        "# Forget Gate Layer\n",
        "\n",
        "#Input Gate Layer\n",
        "#Outputs a number to indicate inside which cells the information should be updated\n",
        "\n",
        "# Output Gate Layer\n",
        "# process occuring -> In the cell state is going through a tanh function, and then it is multiplied by the weighted output of the sigmoid function. \n",
        "\n",
        "# Keras for Attention Layer Support in tensorflow\n",
        "from keras import backend as Back \n",
        "Back.clear_session()\n",
        "\n",
        "facet_a=300 # Latent Dimension -> input data for every iteration\n",
        "facet_e=100\n",
        "# Embedding Dimension -> Result data gathered from every iteration to be sent to next iteration\n",
        "#higher number, the network gets more powerful. Howevery, the number of parameters to learn also rises. This means it needs more time to train the network.\n",
        "\n",
        "podium_i=Input(shape=(MAX_T_L,))\n",
        "# Word embedding is a set of feature learning techniques in NLP where words are mapped to vectors of real numbers.\n",
        "coll_d=Embedding(final_x, facet_e,trainable=True)(podium_i)\n",
        "\n",
        "# 0 means do not let any information pass, while 1 means let all information pass\n",
        "\n",
        "# Stacked LSTM has multiple layers of LSTM stacked on top of each other. \n",
        "# This leads to a better representation of the sequence.\n",
        "\n",
        "# stack 1 LSTM\n",
        "answer_a=LSTM(facet_a, \n",
        "              dropout=0.4, # Attention paid to all the data elements during this iteartion\n",
        "              return_sequences=True, # LSTM produces the hidden state and cell state for every timestep  \n",
        "              recurrent_dropout=0.4, # Attention paid to input data\n",
        "              return_state=True) \n",
        "r1,tell1,tell2=answer_a(coll_d)\n",
        "\n",
        "# stack 2 LSTM\n",
        "answer_b=LSTM(facet_a, \n",
        "              dropout=0.4, # Attention paid to all the data elements during this iteartion\n",
        "              return_sequences=True,  # LSTM produces the hidden state and cell state for every timestep\n",
        "              recurrent_dropout=0.4, # Attention paid to the before result iteration\n",
        "              return_state=True)\n",
        "r2,m2,m3=answer_b(r1)\n",
        "\n",
        "# stack 3 LSTM\n",
        "answer_c=LSTM(facet_a, \n",
        "              dropout=0.4, # Attention paid to all the data elements during this iteartion\n",
        "              return_sequences=True,  # LSTM produces the hidden state and cell state for every timestep\n",
        "              recurrent_dropout=0.4, # Attention paid to the before result iteration\n",
        "              return_state=True)\n",
        "eye_e,item_a,item_b=answer_c(r2)\n",
        "# All information is passed through all the cells while the critical information is kept to the end, no matter how many cells the network has.\n",
        "\n",
        "\n",
        "ins_datum=Input(shape=(None,))\n",
        "# builds a relationship between words and allows calculations among them\n",
        "# Eg:- “king - men + women” = “queen”\n",
        "stack_e=Embedding(final_y, facet_e,trainable=True)\n",
        "podium_d=stack_e(ins_datum)\n",
        "\n",
        "#Final LSTM Decoding for biderectional check\n",
        "dmodule=LSTM(facet_a, \n",
        "              dropout=0.4, # Attention paid to all the data elements during this iteartion\n",
        "              return_sequences=True,  # LSTM produces the hidden state and cell state for every timestep\n",
        "              recurrent_dropout=0.2, # Attention paid to the before result iteration\n",
        "              return_state=True)\n",
        "\n",
        "# Initializing it to a value\n",
        "eye_d,decoder_fwd_state, decoder_back_state=dmodule(podium_d,initial_state=[item_a, item_b])\n",
        "\n",
        "# Attention Layer Object\n",
        "object_m=Algo_attention(name='Algorithm_attention')\n",
        "# check\n",
        "attn_out, attn_states = object_m([eye_e, eye_d])\n",
        "\n",
        "# Concatinating\n",
        "podium_dec_i=Concatenate(axis=-1, name='concat_layer')([eye_d, attn_out])\n",
        "\n",
        "# wrapper allows to apply a layer to every temporal slice of an input\n",
        "# Activation is the element-wise activation function\n",
        "# Softmax converts a real vector to a vector of categorical probabilities, cuz max of (a)t is 1\n",
        "# final_y is the feauture vector with both encoder and decoder data\n",
        "strcpy_p=TimeDistributed(Dense(final_y, activation='softmax'))\n",
        "\n",
        "# making a dense cluster\n",
        "eye_d=strcpy_p(podium_dec_i)\n",
        "\n",
        "#Model creation\n",
        "blue_p=Model([podium_i, ins_datum],eye_d)\n",
        "blue_p.summary() # Model Schema"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 30, 100)      844000      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 30, 300), (N 481200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 30, 300), (N 721200      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    198900      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 30, 300), (N 721200      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "Algorithm_attention (Algo_atten ((None, None, 300),  180300      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
            "                                                                 Algorithm_attention[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 1989)   1195389     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 4,823,389\n",
            "Trainable params: 4,823,389\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Lwfi1Fm8Fxiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Config the model with losses and metrics\n",
        "blue_p.compile(loss='sparse_categorical_crossentropy', #Sparse categorical crossentropy loss value.\n",
        "               optimizer='rmsprop') #Optimizer that implements the RMSprop algorithm."
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-A3J92MUljB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Early stopping is a technique used to terminate the training before overfitting occurs\n",
        "Stope = EarlyStopping(mode='min', # Terminates when quantity monitored has stopped decreasing;\n",
        "                      patience=2, # Terminates if no improvement found for 2 consequtive epochs\n",
        "                      verbose=1, # Output messages which could be useful for debugging\n",
        "                      monitor='val_loss') #Quantity to be monitored for debugging"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ETnPzA4OFxi3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "32df8d6d-42bc-47bc-a788-266930a4a5de"
      },
      "source": [
        "# Train and validate model by fitting\n",
        "wetrain=blue_p.fit([train_x, # initial text data\n",
        "                    train_y[:,:-1]],  # removes last char\n",
        "                   train_y.reshape(train_y.shape[0], # Processed data of summary\n",
        "                   train_y.shape[1], 1)[:,1:], \n",
        "                   callbacks=[Stope],  # Early stopping\n",
        "                   batch_size=128, # Since large dataset, it's set to 128 instead of default 32 \n",
        "                   epochs=10, # Refning the model, generally defined as \"one pass over the entire dataset\". Larger the epoch better refined is the model \n",
        "                   # validating dataset where the model will not be trained\n",
        "                   validation_data=([value_x,value_y[:,:-1]], \n",
        "                                     value_y.reshape(value_y.shape[0],value_y.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "324/324 [==============================] - 207s 638ms/step - loss: 1.9148 - val_loss: 2.0995\n",
            "Epoch 2/10\n",
            "324/324 [==============================] - 205s 633ms/step - loss: 1.8820 - val_loss: 2.0495\n",
            "Epoch 3/10\n",
            "324/324 [==============================] - 202s 622ms/step - loss: 1.8511 - val_loss: 2.0588\n",
            "Epoch 4/10\n",
            "324/324 [==============================] - 202s 625ms/step - loss: 1.8243 - val_loss: 2.0433\n",
            "Epoch 5/10\n",
            "324/324 [==============================] - 206s 635ms/step - loss: 1.7966 - val_loss: 2.0496\n",
            "Epoch 6/10\n",
            "324/324 [==============================] - 207s 638ms/step - loss: 1.7697 - val_loss: 2.0382\n",
            "Epoch 7/10\n",
            "324/324 [==============================] - 203s 627ms/step - loss: 1.7467 - val_loss: 2.0340\n",
            "Epoch 8/10\n",
            "324/324 [==============================] - 203s 628ms/step - loss: 1.7229 - val_loss: 2.0376\n",
            "Epoch 9/10\n",
            "324/324 [==============================] - 203s 628ms/step - loss: 1.6998 - val_loss: 2.0529\n",
            "Epoch 00009: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tDTNLAURFxjE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "6b1b40ff-5bd9-4c87-f682-3a4679e46f94"
      },
      "source": [
        "# Graph to demonstrate the Training vs Testing in the model\n",
        "from matplotlib import pyplot\n",
        "plt.ylabel('data loss')\n",
        "plt.xlabel('count epoch')\n",
        "# .history is inbuilt model function \n",
        "pyplot.plot(wetrain.history['val_loss'], label='Data testing') # Gives how the testing data fared\n",
        "pyplot.plot(wetrain.history['loss'], label='Data Training') # Gives how the training data fared\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sBX0zZnOFxjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenizer method creates the vocabulary index based on word frequency.\n",
        "r_aim_wi=tokens_y.index_word # returns the index_word list of token_y which is summary ->reverse\n",
        "back_data_m=tokens_x.index_word # returns the index_word list of token_x which is texts ->reverse\n",
        "aim_wi=tokens_y.word_index # returns the word_index list of token_y which is summary ->straight\n",
        "# Every word gets a unique integer value.So lower integer means more frequent word"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9QkrNV-4Fxjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "copy_e = Model(inputs=podium_i,outputs=[eye_e, item_a, item_b]) # Creating a model for texts\n",
        "\n",
        "# facet_a is the size considered for every model in this program\n",
        "material_d=Input(shape=(facet_a)) # creating tensors of size which is used for all models\n",
        "material_e=Input(shape=(facet_a)) # creating tensors of size which is used for all models\n",
        "\n",
        "o_stacke=stack_e(ins_datum) # final LSTM encode data of texts\n",
        "\n",
        "m1,m2,m3=dmodule(o_stacke, initial_state=[material_d, material_e]) # inputting text data to summary LSTM\n",
        "\n",
        "material_f = Input(shape=(MAX_T_L,facet_a)) # creating 2d tensors of size which is used for all models with each key size MAX_T_L\n",
        "o_att, s_att = object_m([material_f, m1]) # Applying Attention layer result\n",
        "\n",
        "joined_data = Concatenate(axis=-1, name='concat')([m1, o_att]) # concattinnating LSTM res with Attention layer\n",
        "m1 = strcpy_p(joined_data) # dense cluster \n",
        "\n",
        "copy_d = Model([ins_datum]+[material_f,material_d, material_e],[m1]+[m2, m3]) # Final model creation for summary abstraction"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJFzByLcbQIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sum_conv(blob):\n",
        "    vault='' # Empty string\n",
        "    for kval in blob:\n",
        "        if((kval!=aim_wi['sostok']) and kval!=aim_wi['eostok'] and kval!=0): # if the data is not equal to the two sentimental value given\n",
        "            vault=vault+r_aim_wi[kval]+' '  # Appending data to vault\n",
        "    return vault"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6f6TTFnBFxj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crackit(blob):\n",
        "    result_buff='' # Empty string\n",
        "    flag=False # bool flag\n",
        "    crux_data=np.zeros((1,1)) # zero array\n",
        "    crux_data[0, 0]=aim_wi['sostok'] # inititaling the first data\n",
        "    t1,t2,t3=copy_e.predict(blob) # predict from text model of LSTM\n",
        "    while not flag:\n",
        "        result_tok,po,lo=copy_d.predict([crux_data]+[t1,t2,t3]) # predict from final model for summary of LSTM\n",
        "        tok_pointer=np.argmax(result_tok[0, -1, :]) # Returns indices of the max element of the array in a particular axis\n",
        "        coupon=r_aim_wi[tok_pointer] # Appending max data index to coupon\n",
        "        if (coupon=='eostok' or len(result_buff.split())>=(MAX_S_L-1)):\n",
        "            flag=True # breaks at the end ot at (time when max summary length is increasing at hits 7) extra echeck done\n",
        "        if (coupon!='eostok'): # if not the sentimental value then add\n",
        "            result_buff+=' '+coupon # append data\n",
        "        t2,t3=po,lo # overwritting the text predict\n",
        "        crux_data=np.zeros((1,1)) # re initializing to 0 to save space\n",
        "        crux_data[0,0]=tok_pointer #max_element index\n",
        "\n",
        "    return result_buff"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aAUntznIFxj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def txt_conv(blob):\n",
        "    vault='' # empty string\n",
        "    for kval in blob:\n",
        "        if(kval!=0): # if not empty(NUll or 0)\n",
        "            vault=vault+back_data_m[kval]+' ' #Appending data\n",
        "    return vault"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BUtQmQTmFxkI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        },
        "outputId": "d57e32f1-a3c1-4fac-c83b-188fe02cfe52"
      },
      "source": [
        "# Result dictionary\n",
        "LSTM_RES = {\n",
        "              \"Feedback\": [],\n",
        "              \"Real Result\": [],\n",
        "              \"Predicted Result\": []\n",
        "}\n",
        "for i in range(0,10): # top 10 printing\n",
        "    print(\"Feedback:\",txt_conv(train_x[i])) # Review text\n",
        "    LSTM_RES['Feedback'].append(txt_conv(train_x[i]))\n",
        "    print(\"Real Result:\",sum_conv(train_y[i])) # Original summary\n",
        "    LSTM_RES['Real Result'].append(sum_conv(train_y[i]))\n",
        "    print(\"Predicted Result:\",crackit(train_x[i].reshape(1,MAX_T_L))) # Predicted Summary\n",
        "    LSTM_RES['Predicted Result'].append(crackit(train_x[i].reshape(1,MAX_T_L)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feedback: gave caffeine shakes heart anxiety attack plus tastes unbelievably bad stick coffee tea soda thanks \n",
            "Real Result: hour \n",
            "Predicted Result:  great tea\n",
            "\n",
            "\n",
            "Feedback: got great course good belgian chocolates better \n",
            "Real Result: would like to give it stars but \n",
            "Predicted Result:  great taste\n",
            "\n",
            "\n",
            "Feedback: one best flavored coffees tried usually like flavored coffees one great serve company love \n",
            "Real Result: delicious \n",
            "Predicted Result:  great coffee\n",
            "\n",
            "\n",
            "Feedback: salt separate area pain makes hard regulate salt putting like salt go ahead get product \n",
            "Real Result: tastes ok packaging \n",
            "Predicted Result:  great salt\n",
            "\n",
            "\n",
            "Feedback: really like product super easy order online delivered much cheaper buying gas station stocking good long drives \n",
            "Real Result: turkey jerky is great \n",
            "Predicted Result:  great flavor\n",
            "\n",
            "\n",
            "Feedback: best salad dressing delivered promptly quantities last vidalia onion dressing compares made oak hill farms sometimes find costco order front door want even orders cut shipping costs \n",
            "Real Result: my favorite salad dressing \n",
            "Predicted Result:  great product\n",
            "\n",
            "\n",
            "Feedback: think sitting around warehouse long time took long time send got tea tasted like cardboard red rasberry leaf tea know supposed taste like \n",
            "Real Result: stale \n",
            "Predicted Result:  not so good\n",
            "\n",
            "\n",
            "Feedback: year old cat special diet digestive problems also diabetes stopped eating usual special formula food tried different kinds catfood one liked easy digestion diabetes thank newman \n",
            "Real Result: wonderful \n",
            "Predicted Result:  great for cats\n",
            "\n",
            "\n",
            "Feedback: always perfect snack dog loves knows exactly starts ask time evening gets greenie snack thank excellent product fast delivery \n",
            "Real Result: greenies buddy treat \n",
            "Predicted Result:  great for training\n",
            "\n",
            "\n",
            "Feedback: dog loves tiny treats keep one car one house \n",
            "Real Result: dog loves them \n",
            "Predicted Result:  great treat\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW1UHkdhV-I7",
        "colab_type": "text"
      },
      "source": [
        "Further research using this would be to predict the stars that the review would have got with just texts given.\n",
        "\n",
        "This model is also used to redict the caption of the image by just focusssing on one part og it just like humans"
      ]
    }
  ]
}